{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f032bcd9",
   "metadata": {},
   "source": [
    "Task_C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24111da",
   "metadata": {},
   "source": [
    "Download necessary NLTK resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('brown', quiet=True)\n",
    "\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import brown\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef24e10",
   "metadata": {},
   "source": [
    " Keep picking random sentences until we find NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888162ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Using random Brown sentence:\n",
      "Second , for both sexes , the 21 transverse lines in the Onset Profile vary more in individual spread than those in the Completion Profile .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = brown.sents()\n",
    "doc = None\n",
    "\n",
    "while True:\n",
    "    random_sentence = random.choice(sentences)\n",
    "    text = \" \".join(random_sentence)\n",
    "    doc = nlp(text)\n",
    "    if doc.ents:  \n",
    "        break\n",
    "\n",
    "print(f\"\\n Using random Brown sentence:\\n{text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31db66",
   "metadata": {},
   "source": [
    "Tokenization and NLTK POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5714775b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NLTK POS Tags ===\n",
      "Second: JJ\n",
      ",: ,\n",
      "for: IN\n",
      "both: DT\n",
      "sexes: NNS\n",
      ",: ,\n",
      "the: DT\n",
      "21: CD\n",
      "transverse: NN\n",
      "lines: NNS\n",
      "in: IN\n",
      "the: DT\n",
      "Onset: NNP\n",
      "Profile: NNP\n",
      "vary: VBP\n",
      "more: RBR\n",
      "in: IN\n",
      "individual: JJ\n",
      "spread: NN\n",
      "than: IN\n",
      "those: DT\n",
      "in: IN\n",
      "the: DT\n",
      "Completion: NNP\n",
      "Profile: NNP\n",
      ".: .\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "\n",
    "tagged = pos_tag(tokens)\n",
    "print(\"\\n=== NLTK POS Tags ===\")\n",
    "for word, tag in tagged:\n",
    "    print(f\"{word}: {tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49babc97",
   "metadata": {},
   "source": [
    "spaCy POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "488219b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== spaCy POS Tags ===\n",
      "Second: ADV\n",
      ",: PUNCT\n",
      "for: ADP\n",
      "both: DET\n",
      "sexes: NOUN\n",
      ",: PUNCT\n",
      "the: DET\n",
      "21: NUM\n",
      "transverse: NOUN\n",
      "lines: NOUN\n",
      "in: ADP\n",
      "the: DET\n",
      "Onset: PROPN\n",
      "Profile: PROPN\n",
      "vary: VERB\n",
      "more: ADV\n",
      "in: ADP\n",
      "individual: ADJ\n",
      "spread: NOUN\n",
      "than: ADP\n",
      "those: PRON\n",
      "in: ADP\n",
      "the: DET\n",
      "Completion: PROPN\n",
      "Profile: PROPN\n",
      ".: PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== spaCy POS Tags ===\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text}: {token.pos_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dca4a2",
   "metadata": {},
   "source": [
    "spaCy NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96f8f63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== spaCy NER ===\n",
      "Second -> ORDINAL\n",
      "21 -> CARDINAL\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== spaCy NER ===\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} -> {ent.label_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs561",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
