{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9a928ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Tushar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29453adf",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a87d2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(corpus_path):\n",
    "    with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    processed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = [token.lower() for token in nltk.word_tokenize(sentence)]\n",
    "        processed_sentences.append(['<s>'] + tokens + ['</s>'])\n",
    "        \n",
    "    return processed_sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ed206",
   "metadata": {},
   "source": [
    "n-gram Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8eb8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModel:\n",
    "    \n",
    "    def __init__(self, n, sentences, k=1.0):\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.counts = defaultdict(Counter)\n",
    "        self.vocab = set()\n",
    "        self.train(sentences)\n",
    "\n",
    "    def train(self, sentences):\n",
    "        all_tokens = []\n",
    "        for sentence in sentences:\n",
    "            all_tokens.extend(sentence)\n",
    "            padded_sentence = ['<s>'] * (self.n - 1) + sentence\n",
    "            for i in range(len(padded_sentence) - self.n + 1):\n",
    "                history = tuple(padded_sentence[i : i + self.n - 1])\n",
    "                word = padded_sentence[i + self.n - 1]\n",
    "                self.counts[history][word] += 1\n",
    "        \n",
    "        self.vocab = set(all_tokens)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "\n",
    "    def calculate_prob(self, history, word):\n",
    "        history = tuple(history)\n",
    "        \n",
    "        \n",
    "        numerator = self.counts[history].get(word, 0) + self.k\n",
    "        \n",
    "        history_count = sum(self.counts[history].values())\n",
    "        \n",
    "        denominator = history_count + (self.k * self.vocab_size)\n",
    "\n",
    "        if denominator == 0:\n",
    "\n",
    "            return 1 / self.vocab_size\n",
    "\n",
    "        return numerator / denominator\n",
    "\n",
    "    def calculate_sentence_perplexity(self, sentence):\n",
    "        padded_sentence = ['<s>'] * (self.n - 1) + sentence\n",
    "        log_prob_sum = 0.0\n",
    "        \n",
    "        num_tokens = len(sentence)\n",
    "\n",
    "        if num_tokens == 0:\n",
    "            return float('inf')\n",
    "\n",
    "        for i in range(len(padded_sentence) - self.n + 1):\n",
    "            history = tuple(padded_sentence[i : i + self.n - 1])\n",
    "            word = padded_sentence[i + self.n - 1]\n",
    "            \n",
    "            prob = self.calculate_prob(history, word)\n",
    "            \n",
    "            if prob == 0:\n",
    "                return float('inf')\n",
    "            \n",
    "            log_prob_sum += np.log2(prob)\n",
    "\n",
    "\n",
    "        perplexity = 2 ** (-log_prob_sum / num_tokens)\n",
    "        return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfacd2f7",
   "metadata": {},
   "source": [
    "Data Ingestion with k_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "438cffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 239\n",
      "Training sentences: 191\n",
      "Testing sentences: 48\n"
     ]
    }
   ],
   "source": [
    "bbc_folder = 'BBC'\n",
    "all_sentences = []\n",
    "for filename in os.listdir(bbc_folder):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(bbc_folder, filename)\n",
    "        sentences = preprocess_data(file_path)\n",
    "        all_sentences.extend(sentences)\n",
    "\n",
    "train_sentences, test_sentences = train_test_split(\n",
    "    all_sentences, test_size=0.2, random_state=42 \n",
    ")\n",
    "\n",
    "print(f\"Total sentences: {len(all_sentences)}\")\n",
    "print(f\"Training sentences: {len(train_sentences)}\")\n",
    "print(f\"Testing sentences: {len(test_sentences)}\")\n",
    "\n",
    "models_to_evaluate = {\n",
    "    \"Unigram\": 1,\n",
    "    \"Bigram\": 2,\n",
    "    \"Trigram\": 3\n",
    "}\n",
    "k_values = [0.0, 0.5, 1.0, 5.0] \n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b51d8f",
   "metadata": {},
   "source": [
    "Evaluation Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67ccbf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unigram, Smoothing: No Smoothing (MLE), Mean Perplexity: 197.9589\n",
      "Model: Unigram, Smoothing: Add-k (k=0.5), Mean Perplexity: 408.3495\n",
      "Model: Unigram, Smoothing: Add-k (k=1.0), Mean Perplexity: 381.7473\n",
      "Model: Unigram, Smoothing: Add-k (k=5.0), Mean Perplexity: 402.1481\n",
      "Model: Bigram, Smoothing: No Smoothing (MLE), Mean Perplexity: 8.2587\n",
      "Model: Bigram, Smoothing: Add-k (k=0.5), Mean Perplexity: 389.8500\n",
      "Model: Bigram, Smoothing: Add-k (k=1.0), Mean Perplexity: 463.1084\n",
      "Model: Bigram, Smoothing: Add-k (k=5.0), Mean Perplexity: 672.7263\n",
      "Model: Trigram, Smoothing: No Smoothing (MLE), Mean Perplexity: 1.7481\n",
      "Model: Trigram, Smoothing: Add-k (k=0.5), Mean Perplexity: 642.7935\n",
      "Model: Trigram, Smoothing: Add-k (k=1.0), Mean Perplexity: 702.5768\n",
      "Model: Trigram, Smoothing: Add-k (k=5.0), Mean Perplexity: 850.2898\n"
     ]
    }
   ],
   "source": [
    "for model_name, n in models_to_evaluate.items():\n",
    "    for k in k_values:\n",
    "        \n",
    "        if n == 1:\n",
    "\n",
    "            class UnigramModel(NGramLanguageModel):\n",
    "                def calculate_prob(self, history, word):\n",
    "                    numerator = self.counts[()].get(word, 0) + self.k\n",
    "                    total_tokens = sum(self.counts[()].values())\n",
    "                    denominator = total_tokens + (self.k * self.vocab_size)\n",
    "                    return numerator / denominator\n",
    "            \n",
    "            model = UnigramModel(n, train_sentences, k=k)\n",
    "        else:\n",
    "            model = NGramLanguageModel(n, train_sentences, k=k)\n",
    "\n",
    "        \n",
    "        total_perplexity = 0\n",
    "        sentence_perplexities = []\n",
    "        \n",
    "        for sentence in test_sentences:\n",
    "            ppl = model.calculate_sentence_perplexity(sentence)\n",
    "            sentence_perplexities.append(ppl)\n",
    "\n",
    "        finite_ppls = [p for p in sentence_perplexities if p != float('inf')]\n",
    "        if not finite_ppls:\n",
    "            mean_perplexity = float('inf')\n",
    "        else:\n",
    "            mean_perplexity = np.mean(finite_ppls)\n",
    "            \n",
    "        smoothing_type = f\"Add-k (k={k})\" if k > 0 else \"No Smoothing (MLE)\"\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Smoothing\": smoothing_type,\n",
    "            \"Mean Perplexity\": mean_perplexity\n",
    "        })\n",
    "        print(f\"Model: {model_name}, Smoothing: {smoothing_type}, Mean Perplexity: {mean_perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7d2d21",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dbe3d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Perplexity Evaluation Report \n",
      "  Model          Smoothing  Mean Perplexity\n",
      "Unigram No Smoothing (MLE)       197.958921\n",
      "Unigram      Add-k (k=0.5)       408.349471\n",
      "Unigram      Add-k (k=1.0)       381.747349\n",
      "Unigram      Add-k (k=5.0)       402.148113\n",
      " Bigram No Smoothing (MLE)         8.258747\n",
      " Bigram      Add-k (k=0.5)       389.849993\n",
      " Bigram      Add-k (k=1.0)       463.108376\n",
      " Bigram      Add-k (k=5.0)       672.726309\n",
      "Trigram No Smoothing (MLE)         1.748121\n",
      "Trigram      Add-k (k=0.5)       642.793459\n",
      "Trigram      Add-k (k=1.0)       702.576781\n",
      "Trigram      Add-k (k=5.0)       850.289760\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n Perplexity Evaluation Report \")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a44b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs561",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
